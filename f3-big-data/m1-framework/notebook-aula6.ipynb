{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistemas de Recomendação - Algoritmo ALS\n",
    "\n",
    "O algoritmo Alternating Least Squares (ALS) é uma técnica popular no campo de sistemas de recomendação, especialmente utilizado para a recomendação colaborativa baseada em fatores latentes. O princípio do ALS é decompor a matriz de interação usuário-item, que contém informações como avaliações de produtos ou interações de usuários com itens, em duas matrizes menores de fatores latentes - uma para usuários e outra para itens. Esses fatores latentes representam características subjetivas e ocultas que influenciam as preferências dos usuários e as propriedades dos itens.\n",
    "\n",
    "O ALS funciona alternando entre a fixação de uma das matrizes de fatores latentes (usuários ou itens) e a otimização da outra, minimizando o erro quadrático das previsões comparado às avaliações conhecidas. Essa abordagem trata eficientemente os dados faltantes, que são comuns em sistemas de recomendação, e se adapta bem a grandes conjuntos de dados, sendo altamente escalável. O ALS é especialmente eficaz quando os dados são esparsos e há uma grande quantidade de usuários e itens, tornando-se uma escolha popular em plataformas de streaming, e-commerce e serviços de mídia social."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "      .master(\"local[*]\") \\\n",
    "      .appName(\"postech\") \\\n",
    "      .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos importar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_raw = spark.read.text(\"data/movies.txt\").rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando os valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines_raw.map(lambda row: row.value.split(\"\\t\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo o Schema pros nossos dados e criando um DataFrame com base neles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsRDD = lines.map(lambda p: \n",
    "                        Row(userId=int(p[0]), \n",
    "                            movieId=int(p[1]), \n",
    "                            rating=float(p[2]), \n",
    "                            timestamp=int(p[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|   196|    242|   3.0|881250949|\n",
      "|   186|    302|   3.0|891717742|\n",
      "|    22|    377|   1.0|878887116|\n",
      "|   244|     51|   2.0|880606923|\n",
      "|   166|    346|   1.0|886397596|\n",
      "|   298|    474|   4.0|884182806|\n",
      "|   115|    265|   2.0|881171488|\n",
      "|   253|    465|   5.0|891628467|\n",
      "|   305|    451|   3.0|886324817|\n",
      "|     6|     86|   3.0|883603013|\n",
      "|    62|    257|   2.0|879372434|\n",
      "|   286|   1014|   5.0|879781125|\n",
      "|   200|    222|   5.0|876042340|\n",
      "|   210|     40|   3.0|891035994|\n",
      "|   224|     29|   3.0|888104457|\n",
      "|   303|    785|   3.0|879485318|\n",
      "|   122|    387|   5.0|879270459|\n",
      "|   194|    274|   2.0|879539794|\n",
      "|   291|   1042|   4.0|874834944|\n",
      "|   234|   1184|   2.0|892079237|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.createDataFrame(ratingsRDD)\n",
    "ratings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos separar o nosso dataset em Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = ratings.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos definir os hiperparâmetros do nosso modelo. A estratégia `drop` em *coldStartStrategy* significa que, caso o usuário tenha poucas interações com os itens em nossa base, ele será desconsiderado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_als = ALS(maxIter=5, \n",
    "                regParam=0.01, \n",
    "                userCol=\"userId\", \n",
    "                itemCol=\"movieId\", \n",
    "                ratingCol=\"rating\", \n",
    "                coldStartStrategy=\"drop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos treinar e avaliar o nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+----------+\n",
      "|userId|movieId|rating|timestamp|prediction|\n",
      "+------+-------+------+---------+----------+\n",
      "|   148|    163|   4.0|877021402| 5.7215776|\n",
      "|   148|    168|   5.0|877015900|  3.776377|\n",
      "|   148|    169|   5.0|877020297|   3.79995|\n",
      "|   148|    173|   5.0|877017054|   4.21437|\n",
      "|   148|    214|   5.0|877019882|   3.46442|\n",
      "+------+-------+------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0752966335633836\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", \n",
    "                                labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"RMSE: \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos gerar 10 recomendações para todos os usuários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRec = model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|     1|[{793, 5.9756246}...|\n",
      "|     3|[{909, 7.3104134}...|\n",
      "|     5|[{998, 6.3981543}...|\n",
      "|     6|[{1643, 5.8951826...|\n",
      "|     9|[{253, 12.308793}...|\n",
      "|    12|[{1160, 7.9621253...|\n",
      "|    13|[{464, 6.348189},...|\n",
      "|    15|[{800, 7.9508986}...|\n",
      "|    16|[{534, 7.257537},...|\n",
      "|    17|[{1311, 7.617544}...|\n",
      "|    19|[{1478, 9.177602}...|\n",
      "|    20|[{984, 8.75906}, ...|\n",
      "|    22|[{1129, 8.363482}...|\n",
      "|    26|[{320, 5.305855},...|\n",
      "|    27|[{1438, 7.5094438...|\n",
      "|    28|[{1409, 5.64722},...|\n",
      "|    31|[{967, 7.269172},...|\n",
      "|    34|[{960, 11.1837635...|\n",
      "|    35|[{253, 8.863161},...|\n",
      "|    37|[{1154, 7.2954597...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userRec.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos fazer o inverso, vamos gerar 10 recomendações para todos os itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieRec = model.recommendForAllItems(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieId|     recommendations|\n",
      "+-------+--------------------+\n",
      "|      1|[{282, 7.158555},...|\n",
      "|      3|[{127, 8.492465},...|\n",
      "|      6|[{180, 11.012345}...|\n",
      "|     12|[{820, 7.4876337}...|\n",
      "|     13|[{39, 8.128774}, ...|\n",
      "|     16|[{820, 6.2807603}...|\n",
      "|     20|[{39, 7.128742}, ...|\n",
      "|     22|[{688, 6.7827554}...|\n",
      "|     26|[{39, 7.1450114},...|\n",
      "|     27|[{475, 9.555755},...|\n",
      "|     28|[{688, 6.5880237}...|\n",
      "|     31|[{688, 5.5656867}...|\n",
      "|     34|[{202, 9.75335}, ...|\n",
      "|     40|[{408, 9.0566025}...|\n",
      "|     44|[{39, 9.685296}, ...|\n",
      "|     47|[{820, 9.8515215}...|\n",
      "|     52|[{310, 6.9967775}...|\n",
      "|     53|[{39, 8.481455}, ...|\n",
      "|     65|[{39, 7.5896506},...|\n",
      "|     76|[{127, 6.9921494}...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movieRec.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos pegar os ids dos filmes recomendados para cada usuário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------------------------------------------+\n",
      "|userId|movieId                                                 |\n",
      "+------+--------------------------------------------------------+\n",
      "|1     |[793, 626, 543, 1142, 730, 169, 1143, 1367, 536, 853]   |\n",
      "|3     |[909, 593, 1069, 954, 308, 1397, 574, 950, 641, 1428]   |\n",
      "|5     |[998, 954, 1209, 916, 1206, 1159, 793, 613, 968, 1269]  |\n",
      "|6     |[1643, 718, 1512, 1368, 573, 653, 610, 320, 1203, 493]  |\n",
      "|9     |[253, 1265, 1113, 1245, 947, 219, 1062, 320, 1132, 1273]|\n",
      "+------+--------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "UserRecsItemId = userRec.select(userRec['userId'], \n",
    "                                userRec['recommendations']['movieId'].alias('movieId'))\n",
    "UserRecsItemId.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "vscode_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
